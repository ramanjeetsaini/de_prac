{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imputing missing values with interative imputer\n",
    "    - identify and replace missing values before model prediction\n",
    "    - this is called data imputattion\n",
    "    - use mode in classification and mean/median in regression\n",
    "    - Use InterativeImputer\n",
    "        - estimates missing values by taking them as a fucntion of existing featueres\n",
    "        - improved with each iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enable_interative_imputer (experimental phase)\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(*a dataset with missing values that we want to impute*)\n",
    "imp = IterativeImputer(max_iter=10, verbose=0)\n",
    "imp.fit(df)\n",
    "impute_df = imp.transform(df)\n",
    "impute_df = pd.DataFrame(impute_df, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating random dummy data \n",
    "- placeholder for testing\n",
    "- should be evaluted carefully to prevent unintended results \n",
    "- make_classification() for classification \n",
    "- make_regression() for regression \n",
    "- set parameters like samples and features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pickle for model persisitenace\n",
    " - model persistance allows us to use without retraining \n",
    " - SKlearn's pickle allows model reuse and achieve model persistence \n",
    " - can be loaded anytime for model predictions \n",
    " - for serializing algorithm , can use pickle or joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# Save a KNN model \n",
    "saved_model = pickle.dumps(knn)\n",
    "# Load a saved KNN model\n",
    "load_model = pickle.loads(saved_model)\n",
    "# Make new predictions from a pickled model \n",
    "load_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix\n",
    "- describe classifier's performacne for test data\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating visualization using decision trees\n",
    "- tree is made up of nodes and corresponsing attributes\n",
    "- visualiza with matplotlib using tree.plot_tree \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
